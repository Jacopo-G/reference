{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19a012d8",
   "metadata": {},
   "source": [
    "# Scikit-Learn Reference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5908e6c",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03aa7095",
   "metadata": {},
   "source": [
    "# Table of Contents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "362dcd08",
   "metadata": {},
   "source": [
    "## [Data Class ](#Data-Class)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "805e097b",
   "metadata": {},
   "source": [
    "## [Load Data ](#Load-Data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29df158f",
   "metadata": {},
   "source": [
    "## [Prep Data ](#Prep-Data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc0716de",
   "metadata": {},
   "source": [
    "### &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[Bag of Words Vectorization ](#Bag-of-Words-Vectorization)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea5a80f0",
   "metadata": {},
   "source": [
    "## [Classification ](#Classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a94f61b7",
   "metadata": {},
   "source": [
    "### &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[Linear SVM ](#Linear-SVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e07ab1e",
   "metadata": {},
   "source": [
    "### &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[Decision Tree ](#Decision-Tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f6d04db",
   "metadata": {},
   "source": [
    "### &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[Naive Bayes ](#Naive-Bayes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1935fa11",
   "metadata": {},
   "source": [
    "### &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[Logistic-Regression ](#Logistic-Regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e37080",
   "metadata": {},
   "source": [
    "## [Evaluation ](#Evaluation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8543999",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbcd992b",
   "metadata": {},
   "source": [
    "# Data Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b80814f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "class Sentiment:\n",
    "    NEGATIVE = \"NEGATIVE\"\n",
    "    NEUTRAL = \"NEUTRAL\"\n",
    "    POSITIVE = \"POSITIVE\"\n",
    "\n",
    "class Review:\n",
    "    def __init__(self, text, score):\n",
    "        self.text = text\n",
    "        self.score = score\n",
    "        self.sentiment = self.get_sentiment()\n",
    "    def get_sentiment(self):\n",
    "        if self.score <= 2:\n",
    "            return Sentiment.NEGATIVE\n",
    "        elif self.score == 3:\n",
    "            return Sentiment.NEUTRAL\n",
    "        else: # score of 4 or 5\n",
    "            return Sentiment.POSITIVE\n",
    "class ReviewContainer:\n",
    "    def __init__(self, reviews):\n",
    "        self.reviews = reviews\n",
    "    \n",
    "    def get_text(self):\n",
    "        return [x.text for x in self.reviews]\n",
    "        \n",
    "    def get_sentiment(self):\n",
    "        return [x.sentiment for x in self.reviews]\n",
    "    \n",
    "    def evenly_distribute(self):\n",
    "        negative = list(filter(lambda x: x.sentiment == Sentiment.NEGATIVE, self.reviews))\n",
    "        positive = list(filter(lambda x: x.sentiment == Sentiment.POSITIVE, self.reviews))\n",
    "        positive_shrunk = positive[:len(negative)]\n",
    "        self.reviews = negative + positive_shrunk\n",
    "        random.shuffle(self.reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5545a0b1",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "266fcce3",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09d03bb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'POSITIVE'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "file_name = \"./data/sentiment/books_small_10000.json\"\n",
    "reviews = []\n",
    "with open(file_name) as f:\n",
    "    for line in f:\n",
    "        review = json.loads(line)\n",
    "        reviews.append(Review(review[\"reviewText\"], review[\"overall\"]))\n",
    "reviews[342].sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1627b1",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f5b00cd",
   "metadata": {},
   "source": [
    "# Prep Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "847a8497",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "training, test = train_test_split(reviews, test_size=0.33, random_state=42)\n",
    "\n",
    "train_container = ReviewContainer(training)\n",
    "test_container = ReviewContainer(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47e1052b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "436\n",
      "436\n"
     ]
    }
   ],
   "source": [
    "train_container.evenly_distribute()\n",
    "train_x = train_container.get_text()\n",
    "train_y = train_container.get_sentiment()\n",
    "\n",
    "test_container.evenly_distribute()\n",
    "test_x = test_container.get_text()\n",
    "test_y = test_container.get_sentiment()\n",
    "\n",
    "print(train_y.count(Sentiment.POSITIVE))\n",
    "print(train_y.count(Sentiment.NEGATIVE))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b641f3",
   "metadata": {},
   "source": [
    "### Bag of Words Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7666e52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 4277)\t2\n",
      "  (0, 8608)\t1\n",
      "  (0, 4190)\t1\n",
      "  (0, 8052)\t1\n",
      "  (0, 3068)\t1\n",
      "  (0, 5589)\t1\n",
      "  (0, 3899)\t1\n",
      "  (0, 5354)\t1\n",
      "  (0, 7303)\t1\n",
      "  (0, 5478)\t1\n",
      "  (0, 7929)\t3\n",
      "  (0, 6145)\t1\n",
      "  (0, 4034)\t1\n",
      "  (0, 991)\t1\n",
      "  (0, 525)\t1\n",
      "  (0, 1790)\t1\n",
      "  (0, 3669)\t1\n",
      "  (0, 805)\t1\n",
      "  (0, 5563)\t1\n",
      "  (0, 870)\t1\n",
      "  (0, 1168)\t1\n",
      "  (0, 2688)\t1\n",
      "  (0, 7603)\t1\n",
      "  (0, 4954)\t1\n"
     ]
    }
   ],
   "source": [
    " from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "train_x_vectors = vectorizer.fit_transform(train_x)\n",
    "\n",
    "test_x_vectors = vectorizer.transform(test_x)\n",
    "\n",
    "print(train_x_vectors[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a055b3b6",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd2bd01",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16dfa8a9",
   "metadata": {},
   "source": [
    "### Linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd6d49c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['POSITIVE']\n",
      "With so much action going on and so many perspectives to tell the story from, &#34;Black Hawk Down&#34; give a truly in-depth look at what happened over the course of less than a day, but just like the fog of war confuses those within it, the mashing of multiple story lines challenges the reader to do lots of work on keeping up with who is where and doing what. This gets easier as the book moves along because the names and locations become more familiar, but to truly understand the first half of the book, one must read it again with the accumulated knowledge of having read the entire book. Other than that, it was written so that the non-military mind can understand the various situations with limited knowledge of tactical jargon and that's a good thing for those of us who do not have a military background but enjoy reading books about the history of our military to get a better appreciation at what they do to provide security for Americans and allies alike. \n",
      " POSITIVE\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "clf_svm = svm.SVC(kernel=\"linear\")\n",
    "clf_svm.fit(train_x_vectors, train_y)\n",
    "print(clf_svm.predict(test_x_vectors[0]))\n",
    "\n",
    "print(test_x[0], \"\\n\", test_y[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1804ee0",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5cd5f035",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['POSITIVE']\n",
      "With so much action going on and so many perspectives to tell the story from, &#34;Black Hawk Down&#34; give a truly in-depth look at what happened over the course of less than a day, but just like the fog of war confuses those within it, the mashing of multiple story lines challenges the reader to do lots of work on keeping up with who is where and doing what. This gets easier as the book moves along because the names and locations become more familiar, but to truly understand the first half of the book, one must read it again with the accumulated knowledge of having read the entire book. Other than that, it was written so that the non-military mind can understand the various situations with limited knowledge of tactical jargon and that's a good thing for those of us who do not have a military background but enjoy reading books about the history of our military to get a better appreciation at what they do to provide security for Americans and allies alike. \n",
      " POSITIVE\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "clf_dec = DecisionTreeClassifier()\n",
    "clf_dec.fit(train_x_vectors, train_y)\n",
    "\n",
    "print(clf_dec.predict(test_x_vectors[0]))\n",
    "\n",
    "print(test_x[0], \"\\n\", test_y[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70d731c",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7eebfdf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['POSITIVE']\n",
      "With so much action going on and so many perspectives to tell the story from, &#34;Black Hawk Down&#34; give a truly in-depth look at what happened over the course of less than a day, but just like the fog of war confuses those within it, the mashing of multiple story lines challenges the reader to do lots of work on keeping up with who is where and doing what. This gets easier as the book moves along because the names and locations become more familiar, but to truly understand the first half of the book, one must read it again with the accumulated knowledge of having read the entire book. Other than that, it was written so that the non-military mind can understand the various situations with limited knowledge of tactical jargon and that's a good thing for those of us who do not have a military background but enjoy reading books about the history of our military to get a better appreciation at what they do to provide security for Americans and allies alike. \n",
      " POSITIVE\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "clf_gnb = DecisionTreeClassifier()\n",
    "clf_gnb.fit(train_x_vectors, train_y)\n",
    "\n",
    "print(clf_gnb.predict(test_x_vectors[0]))\n",
    "\n",
    "print(test_x[0], \"\\n\", test_y[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69728c66",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "00ca9f0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['POSITIVE']\n",
      "With so much action going on and so many perspectives to tell the story from, &#34;Black Hawk Down&#34; give a truly in-depth look at what happened over the course of less than a day, but just like the fog of war confuses those within it, the mashing of multiple story lines challenges the reader to do lots of work on keeping up with who is where and doing what. This gets easier as the book moves along because the names and locations become more familiar, but to truly understand the first half of the book, one must read it again with the accumulated knowledge of having read the entire book. Other than that, it was written so that the non-military mind can understand the various situations with limited knowledge of tactical jargon and that's a good thing for those of us who do not have a military background but enjoy reading books about the history of our military to get a better appreciation at what they do to provide security for Americans and allies alike. \n",
      " POSITIVE\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf_log = DecisionTreeClassifier()\n",
    "clf_log.fit(train_x_vectors, train_y)\n",
    "\n",
    "print(clf_log.predict(test_x_vectors[0]))\n",
    "\n",
    "print(test_x[0], \"\\n\", test_y[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "356f81ef",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b67e898",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dff76978",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7980769230769231\n",
      "0.6274038461538461\n",
      "0.6490384615384616\n",
      "0.6442307692307693\n"
     ]
    }
   ],
   "source": [
    "# Mean Accuracy\n",
    "print(clf_svm.score(test_x_vectors, test_y))\n",
    "print(clf_dec.score(test_x_vectors, test_y))\n",
    "print(clf_gnb.score(test_x_vectors, test_y))\n",
    "print(clf_log.score(test_x_vectors, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9ed42635",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8028169  0.79310345]\n",
      "[0.63529412 0.61916462]\n",
      "[0.6507177 0.647343 ]\n",
      "[0.63902439 0.6492891 ]\n"
     ]
    }
   ],
   "source": [
    "# F1 Score\n",
    "from sklearn.metrics import f1_score\n",
    "print(f1_score(test_y, clf_svm.predict(test_x_vectors), average=None,\n",
    "         labels=[Sentiment.POSITIVE, Sentiment.NEGATIVE]))\n",
    "print(f1_score(test_y, clf_dec.predict(test_x_vectors), average=None,\n",
    "         labels=[Sentiment.POSITIVE, Sentiment.NEGATIVE]))\n",
    "print(f1_score(test_y, clf_gnb.predict(test_x_vectors), average=None,\n",
    "         labels=[Sentiment.POSITIVE, Sentiment.NEGATIVE]))\n",
    "print(f1_score(test_y, clf_log.predict(test_x_vectors), average=None,\n",
    "         labels=[Sentiment.POSITIVE, Sentiment.NEGATIVE]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d829e65a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "436"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y.count(Sentiment.POSITIVE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
